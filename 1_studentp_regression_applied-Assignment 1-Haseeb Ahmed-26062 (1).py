# -*- coding: utf-8 -*-
"""1_studentp_Regression_Applied

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12YH7-MUWVkIBk8tSYocEk7va7mbAQ0Cd

# **Dataset: Student Performance**

# **Objective:**

Apply Multiple Linear Regression Model on Student Performance dataset and train the model on the dataset to finally predict results on testing data.


**Task**

Our task is to:


*   Preprocess the data, which includes feature scaling, outlier detection and treatment, checking normality of residuals, and  visualizing the data (use libraries i.e., matplotlib and seaborn).
*   Model the data using a multiple linear regression model.

# **Table of Contents**



1. **Data Preprocessing**

 1.1 Importing Libraries
 - Cell 1: Importing necessary libraries
 - Cell 2: Importing warnings
 - Cell 3: File upload
 1.2 Understanding the Dataset
 - Cell 4: Displaying the first few rows of the dataset
 - Cell 5: Checking dataset shape
 - Cell 6: Examining datatypes in each column
 - Cell 7: Basic data information
 - Cell 8: Summary statistics
 1.3 Handling Duplicate and Missing Values
 - Cell 9: Checking for duplicate rows
 - Cell 10: Encoding categorical feature 'Extracurricular Activities'
 - Cell 11: Counting rows
 - Cell 12: Checking for null values
 - Cell 13: Counting nulls per column
 - Cell 14: Dropping nulls
 - Cell 15: Heatmap to visualize any missing data
 1.4 Target Variable and Feature Distribution
 - Cell 16: Distribution plot for 'Performance Index'
 1.5 Correlation Analysis and Variance Inflation Factor (VIF)
 - Cell 17: Correlation matrix plot
 - Cell 18: Calculating VIF for each numerical feature

2. **Exploratory Data Analysis (EDA) with Visualizations**

 2.1 Distribution and Scatter Plots
 - Cell 19: Scatter plot of 'Hours Studied' vs. 'Performance Index'
 - Cell 19: Scatter plot of 'Previous Scores' vs. 'Performance Index'
 2.2 Outlier Detection
 - Cell 20: Boxplot for outliers in 'Performance Index'
 2.3 Count Plot
 - Cell 21: Count plot for 'Extracurricular Activities'
3. **Linear Regression Model**

 3.1 Model Setup and Feature Selection
 - Cell 22: Statistical model setup and summary
 - Cell 23: Dropping dependent variable from independent variables
 3.2 Data Preparation for Regression
 - Cell 24-25: Shaping X (features) and y (target)
 - Cell 26: Splitting data into training and testing sets
 3.3 Model Training and Prediction
 - Cell 27-28: Training X and y
 - Cell 29-30: Testing X and y
 - Cell 31: Calling and fitting linear regression model
 - Cell 32: Testing the model
 3.4 Model Evaluation and Residual Analysis
 - Cell 33: Scatter plot of actual vs. predicted data points
 - Cell 34: Comparing actual and predicted values
 - Cell 35: Calculating residuals
 - Cell 36: Residual plot by order of observations
 - Cell 37: Residual plot vs. fitted values
 - Cell 38: Histogram and Q-Q plots of residuals for normality check
 3.5 Model Performance Metrics
 - Cell 39: Calculating Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)
 - Cell 40: Model evaluation with R-squared and RMSE

## **About the Dataset:**

The Student Performance Dataset explores factors affecting student achievement, covering 10,000 records with various predictors and a performance index:

- Hours Studied: Total hours each student studied.
- Previous Scores: Past test scores of students.
- Extracurricular Activities: Indicates if the student is involved in extracurriculars (Yes/No).
- Sleep Hours: Average daily sleep hours.
- Sample Question Papers Practiced: Number of sample papers practiced by each student.
- Performance Index: Overall academic performance, ranging from 10 to 100, with higher scores indicating better results.

# **Data Preprocessing**
"""

# Cell 1.  Import all the necessary libraries

from google.colab import files

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


from sklearn.feature_selection import SelectKBest, f_regression
from scipy import stats

import warnings
warnings.filterwarnings('ignore')

# Step 1: Upload the file
uploaded = files.upload()

# Step 2: Load the CSV file into a DataFrame
file_name = next(iter(uploaded))  # Get the uploaded file's name
df = pd.read_excel('/content/Student_Performance.csv')

# Step 3: Display the first few rows of the DataFrame
df.head()

df.shape

df.dtypes

df.info()

print("\nDescriptive Statistics:")
df.describe()

duplicate_rows_in_data =df[df.duplicated()]
print("No. of Duplicate rows", duplicate_rows_in_data.shape)
duplicate_rows_in_data

# Convert categorical column 'Extracurricular Activities' into numeric (1 for Yes, 0 for No)
df['Extracurricular Activities'] = df['Extracurricular Activities'].apply(lambda x: 1 if x == 'Yes' else 0)

df.head()

"""**Point of attention 01: Dummy variable trap**


* Our categorical column has just two values (1 and 0), it's already in a form that a model can handle without any issues.
* Hence, we don't need to apply drop_first=True because there are no multiple dummy variables that could cause multicollinearity.

**Point of attention 02: Dropping duplicate rows**


"""

df.count()

df.isnull()

df.isnull().sum()

# we should drop missing values if any, it would drop all row if found any missing value
df=df.dropna()

df.count()

sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='tab20c_r')
plt.title('Missing Data: Training Set')
plt.show()

"""It means there are no missing values in the dataset"""

# Plot the distribution of the target variable 'Performance Index'
plt.figure(figsize=(6, 4))
sns.histplot(df['Performance Index'], kde=True, color='blue')
plt.title('Distribution of Performance Index')
plt.xlabel('Performance Index')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(5, 3))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.xticks(rotation=45, ha='right')
plt.show()

import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

# Assuming 'df' is your dataframe with the independent variables

# Select only numerical features for VIF calculation
numerical_df = df.select_dtypes(include=['number'])

# Add a constant to the model
X = add_constant(numerical_df)

# Create a dataframe to store VIF values
vif = pd.DataFrame()
vif["Feature"] = X.columns
# Calculate VIF for each numerical feature
vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

print(vif)

# Scatter plot between 'Hours Studied' and 'Performance Index'
plt.figure(figsize=(6, 4))
sns.scatterplot(x='Hours Studied', y='Performance Index', data=df, color='green')
plt.title('Hours Studied vs. Performance Index')
plt.xlabel('Hours Studied')
plt.ylabel('Performance Index')
plt.show()

# Scatter plot between 'Previous Scores' and 'Performance Index'
plt.figure(figsize=(6, 4))
sns.scatterplot(x='Previous Scores', y='Performance Index', data=df, color='purple')
plt.title('Previous Scores vs. Performance Index')
plt.xlabel('Previous Scores')
plt.ylabel('Performance Index')
plt.show()

# Boxplot for detecting outliers in 'Performance Index'
plt.figure(figsize=(6, 4))
sns.boxplot(y='Performance Index', data=df, color='orange')
plt.title('Boxplot of Performance Index')
plt.ylabel('Performance Index')
plt.show()

# Count plot for 'Extracurricular Activities' to check the distribution of students involved in activities
plt.figure(figsize=(6, 4))
sns.countplot(x='Extracurricular Activities', data=df, palette='Set2')
plt.title('Distribution of Extracurricular Activities')
plt.xlabel('Extracurricular Activities (1 = Yes, 0 = No)')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(6, 4))
sns.scatterplot(x='Extracurricular Activities', y='Performance Index', data=df, color='purple')
plt.title('Extracurricular Activities vs. Performance Index')
plt.xlabel('Extracurricular Activities')
plt.ylabel('Performance Index')
plt.show()

import statsmodels.api as sm

# Define the independent variables (your features)
X = df[['Hours Studied', 'Previous Scores', 'Extracurricular Activities', 'Sleep Hours', 'Sample Question Papers Practiced']]

# Dependent variable (target)
y = df['Performance Index']

# Add constant (for intercept)
X = sm.add_constant(X)

# Fit the multiple linear regression model
model = sm.OLS(y, X).fit()

# Print model summary
print(model.summary())

# Drop 'Performance Index' from df to create x
x = df.drop('Performance Index', axis=1)

# Assign 'Performance Index' to y
y = df['Performance Index']

x.shape

y.shape

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)

x_train.shape
x_train

y_train

x_test

y_test

linear_reg =LinearRegression()

linear_reg.fit(x_train,y_train)

"""### **Model Testing**"""

y_pred=linear_reg.predict(x_test)
print(y_pred.shape)
print(y_pred)

sns.scatterplot(x=y_test,y=y_pred,color='green',label='Actual Data Points')
sns.lineplot(x=[min(y_test),max(y_test)],y=[min(y_pred),max(y_pred)] , color='red',label='Predicted/IDEAL Line')
plt.legend()
plt.show

#combine actual and predicted values

results=np.column_stack([y_test,y_pred])
print('Actual Values  |    Predicted Values')
print('____________________________________')

for actual,predicted in results:
  print(f'{actual:15.2f}  |  {predicted:15.2f}')

residual=actual-y_pred
print(residual)

residuals=y_test-y_pred
print(residuals)

# Plot residuals over the order of observations to check independence
plt.figure(figsize=(6, 4))
plt.plot(range(len(residuals)), residuals, marker='o', linestyle='', color='blue')
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Independence Check: Residuals over Observations')
plt.xlabel('Observation Order')
plt.ylabel('Residuals')
plt.show()

"""Yes, it is independent


Independent --> yes
"""

# Plot residuals vs. fitted values to check homoscedasticity
plt.figure(figsize=(6, 4))
plt.scatter(y_pred, residuals, color='blue')
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Homoscedasticity Check: Residuals vs. Predicted Values')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.show()

"""It is Homoscedastic"""

# Histogram of residuals to check normality
plt.figure(figsize=(6, 4))
sns.histplot(residuals, kde=True, color='darkgreen')
plt.title('Normality Check: Histogram of Residuals')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()

# Q-Q plot to further check for normality
import scipy.stats as stats
fig, ax = plt.subplots(figsize=(6, 4))
stats.probplot(residuals, dist="norm", plot=ax)
plt.title('Q-Q Plot of Residuals')
plt.show()

"""It is almost a normal chart both in prediction and actual dataset.

### **Model Evaluation**
"""

from sklearn.metrics import mean_squared_error

print("Linear Regression Model")
mse=mean_squared_error(y_test, y_pred)
rmse=np.sqrt(mse)
print("MSE: ", mse)
print("RMSE: ", rmse)

# Evaluating the model using R-squared and RMSE
r2 = r2_score(y_test, y_pred)

print(f"R-squared: {r2}")

"""Model is 98.8% expressible by the independent varabiales we have taken.

Model is quite Expressible.
"""

print('Coefficients: ', model.coef_)

model.score(X,y)

"""# **Questions**

1. What role do the coefficients (slopes) play in Linear Regression? How would you interpret them in the context of our dataset?

2. What are the independent (predictor) and dependent (target) variables in this dataset?

3. What happens when we increase the number of features (independent variables) in a Linear Regression model? How does it affect accuracy?

4. What does the output summary of the model tell us about the statistical significance of each feature?

5. If we observe that the model has high training accuracy but low testing accuracy, what does that indicate?
"""

# Answers:

# Q1) Coefficients indicate the amount by which the Performance Index is altered for an increase in one unit of a predictor variable when others are held constant.

# Q2) Independant: Hours Studied, Previous Scores, Extracurricular Activities, Sleep Hours, Sample Question Papers Practiced
#     Dependant: Performance Index

# Q3) More features enhance accuracy But too many features lead to overfitting.

# Q4) The model summary gives:
#     Coefficients: Strength and direction of relationships.
#     p-values: If p < 0.05, the feature has a significant effect on Performance Index.
#     R-squared: The goodness of fit of the model to the variability in Performance Index.

# Q5) This indicates overfitting, i.e., the model is over-fit to the training data but not able to generalize to new data.